{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pdfplumber pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHMzH_u6pg_S",
        "outputId": "d038f984-76db-4663-df42-2f040edf47ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "twJOmVg4oA9K"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import libraries\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your file path\n",
        "pdf_filename = '/content/drive/MyDrive/Soma/senior-schools-in-kenya.pdf'\n",
        "print(f\"File path set to: {pdf_filename}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0jUsyPKpnNT",
        "outputId": "2ee7b160-4a4f-4392-e893-39853a97923f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File path set to: /content/drive/MyDrive/Soma/senior-schools-in-kenya.pdf\n",
            "âœ… File found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This PDF extraction function implements a two-stage approach to handle different PDF formats reliably. Here's how it works:\n",
        "\n",
        "Initial Setup & Page Processing: The function opens the PDF file, counts total pages, and processes each page sequentially while providing progress feedback to track extraction status.\n",
        "\n",
        "Primary Method - Table Detection: It first attempts structured table extraction using page.extract_tables(), which works best for PDFs with properly formatted table structures. When tables are found, it validates each row by checking if the first column contains a number (indicating a valid school record), then maps the 12 expected columns (S/No through Gender) to a dictionary structure.\n",
        "Fallback Method - Text Parsing: If no tables are detected, the function switches to raw text extraction using page.extract_text(). It splits the text into lines, identifies data rows using regex pattern ^\\d+\\s (lines starting with numbers), and splits these lines by multiple spaces or tabs to separate the columns.\n",
        "\n",
        "Data Validation & Structure: Both methods create standardized dictionaries with consistent field names (S_No, REGION, COUNTY, SUB_COUNTY, UIC, KNEC, SCHOOL_NAME, CLUSTER, TYPE, DISABILITY_TYPE, ACCOMMODATION_TYPE, GENDER), ensuring uniform output regardless of extraction method.\n",
        "\n",
        "Debugging & Error Handling: The function includes comprehensive logging that shows pages processed, tables found, total rows extracted, and sample data. If extraction fails completely, it displays the first 1000 characters of raw PDF content to help diagnose formatting issues.\n",
        "\n",
        "Robust Column Handling: The code safely handles varying column counts using conditional checks (if len(parts) > X) and provides empty strings for missing columns, preventing index errors when PDFs have inconsistent formatting or missing data fields."
      ],
      "metadata": {
        "id": "U5uxw0bqtPg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_school_data(pdf_path):\n",
        "    rows = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        print(f\"PDF has {len(pdf.pages)} pages\")\n",
        "\n",
        "        for page_num, page in enumerate(pdf.pages):\n",
        "            print(f\"Processing page {page_num + 1}...\")\n",
        "\n",
        "            # Try table extraction first\n",
        "            tables = page.extract_tables()\n",
        "            if tables:\n",
        "                print(f\"Found {len(tables)} table(s) on page {page_num + 1}\")\n",
        "                for table in tables:\n",
        "                    for row in table[1:]:  # Skip header\n",
        "                        if row and len(row) >= 8 and row[0] and row[0].strip().isdigit():\n",
        "                            data_row = {\n",
        "                                'S_No': row[0].strip() if row[0] else '',\n",
        "                                'REGION': row[1].strip() if len(row) > 1 and row[1] else '',\n",
        "                                'COUNTY': row[2].strip() if len(row) > 2 and row[2] else '',\n",
        "                                'SUB_COUNTY': row[3].strip() if len(row) > 3 and row[3] else '',\n",
        "                                'UIC': row[4].strip() if len(row) > 4 and row[4] else '',\n",
        "                                'KNEC': row[5].strip() if len(row) > 5 and row[5] else '',\n",
        "                                'SCHOOL_NAME': row[6].strip() if len(row) > 6 and row[6] else '',\n",
        "                                'CLUSTER': row[7].strip() if len(row) > 7 and row[7] else '',\n",
        "                                'TYPE': row[8].strip() if len(row) > 8 and row[8] else '',\n",
        "                                'DISABILITY_TYPE': row[9].strip() if len(row) > 9 and row[9] else '',\n",
        "                                'ACCOMMODATION_TYPE': row[10].strip() if len(row) > 10 and row[10] else '',\n",
        "                                'GENDER': row[11].strip() if len(row) > 11 and row[11] else ''\n",
        "                            }\n",
        "                            rows.append(data_row)\n",
        "\n",
        "            # If no tables found, try text extraction\n",
        "            if not tables:\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    lines = text.split('\\n')\n",
        "                    for line in lines:\n",
        "                        line = line.strip()\n",
        "                        # Look for lines starting with numbers\n",
        "                        if re.match(r'^\\d+\\s', line):\n",
        "                            # Split by multiple spaces or tabs\n",
        "                            parts = re.split(r'\\s{2,}|\\t+', line)\n",
        "\n",
        "                            if len(parts) >= 8:\n",
        "                                data_row = {\n",
        "                                    'S_No': parts[0].strip(),\n",
        "                                    'REGION': parts[1].strip() if len(parts) > 1 else '',\n",
        "                                    'COUNTY': parts[2].strip() if len(parts) > 2 else '',\n",
        "                                    'SUB_COUNTY': parts[3].strip() if len(parts) > 3 else '',\n",
        "                                    'UIC': parts[4].strip() if len(parts) > 4 else '',\n",
        "                                    'KNEC': parts[5].strip() if len(parts) > 5 else '',\n",
        "                                    'SCHOOL_NAME': parts[6].strip() if len(parts) > 6 else '',\n",
        "                                    'CLUSTER': parts[7].strip() if len(parts) > 7 else '',\n",
        "                                    'TYPE': parts[8].strip() if len(parts) > 8 else '',\n",
        "                                    'DISABILITY_TYPE': parts[9].strip() if len(parts) > 9 else '',\n",
        "                                    'ACCOMMODATION_TYPE': parts[10].strip() if len(parts) > 10 else '',\n",
        "                                    'GENDER': parts[11].strip() if len(parts) > 11 else ''\n",
        "                                }\n",
        "                                rows.append(data_row)\n",
        "\n",
        "    print(f\"Extracted {len(rows)} rows total\")\n",
        "    return rows\n",
        "\n",
        "# Extract data\n",
        "school_data = extract_school_data(pdf_filename)\n",
        "\n",
        "# Debug: Show first few raw extractions\n",
        "if school_data:\n",
        "    print(\"Sample extracted data:\")\n",
        "    for i, row in enumerate(school_data[:3]):\n",
        "        print(f\"Row {i+1}: {row}\")\n",
        "else:\n",
        "    print(\"No data extracted. Let's debug the PDF content...\")\n",
        "\n",
        "    # Debug: Show raw text from first page\n",
        "    with pdfplumber.open(pdf_filename) as pdf:\n",
        "        first_page_text = pdf.pages[0].extract_text()\n",
        "        print(\"First 1000 characters of page 1:\")\n",
        "        print(first_page_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zm_H36up15I",
        "outputId": "06c7b3e0-b6e9-4220-b54c-90b9f0a88f54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF has 248 pages\n",
            "Processing page 1...\n",
            "Found 1 table(s) on page 1\n",
            "Processing page 2...\n",
            "Found 1 table(s) on page 2\n",
            "Processing page 3...\n",
            "Found 1 table(s) on page 3\n",
            "Processing page 4...\n",
            "Found 1 table(s) on page 4\n",
            "Processing page 5...\n",
            "Found 1 table(s) on page 5\n",
            "Processing page 6...\n",
            "Found 1 table(s) on page 6\n",
            "Processing page 7...\n",
            "Found 1 table(s) on page 7\n",
            "Processing page 8...\n",
            "Found 1 table(s) on page 8\n",
            "Processing page 9...\n",
            "Found 1 table(s) on page 9\n",
            "Processing page 10...\n",
            "Found 1 table(s) on page 10\n",
            "Processing page 11...\n",
            "Found 1 table(s) on page 11\n",
            "Processing page 12...\n",
            "Found 1 table(s) on page 12\n",
            "Processing page 13...\n",
            "Found 1 table(s) on page 13\n",
            "Processing page 14...\n",
            "Found 1 table(s) on page 14\n",
            "Processing page 15...\n",
            "Found 1 table(s) on page 15\n",
            "Processing page 16...\n",
            "Found 1 table(s) on page 16\n",
            "Processing page 17...\n",
            "Found 1 table(s) on page 17\n",
            "Processing page 18...\n",
            "Found 1 table(s) on page 18\n",
            "Processing page 19...\n",
            "Found 1 table(s) on page 19\n",
            "Processing page 20...\n",
            "Found 1 table(s) on page 20\n",
            "Processing page 21...\n",
            "Found 1 table(s) on page 21\n",
            "Processing page 22...\n",
            "Found 1 table(s) on page 22\n",
            "Processing page 23...\n",
            "Found 1 table(s) on page 23\n",
            "Processing page 24...\n",
            "Found 1 table(s) on page 24\n",
            "Processing page 25...\n",
            "Found 1 table(s) on page 25\n",
            "Processing page 26...\n",
            "Found 1 table(s) on page 26\n",
            "Processing page 27...\n",
            "Found 1 table(s) on page 27\n",
            "Processing page 28...\n",
            "Found 1 table(s) on page 28\n",
            "Processing page 29...\n",
            "Found 1 table(s) on page 29\n",
            "Processing page 30...\n",
            "Found 1 table(s) on page 30\n",
            "Processing page 31...\n",
            "Found 1 table(s) on page 31\n",
            "Processing page 32...\n",
            "Found 1 table(s) on page 32\n",
            "Processing page 33...\n",
            "Found 1 table(s) on page 33\n",
            "Processing page 34...\n",
            "Found 1 table(s) on page 34\n",
            "Processing page 35...\n",
            "Found 1 table(s) on page 35\n",
            "Processing page 36...\n",
            "Found 1 table(s) on page 36\n",
            "Processing page 37...\n",
            "Found 1 table(s) on page 37\n",
            "Processing page 38...\n",
            "Found 1 table(s) on page 38\n",
            "Processing page 39...\n",
            "Found 1 table(s) on page 39\n",
            "Processing page 40...\n",
            "Found 1 table(s) on page 40\n",
            "Processing page 41...\n",
            "Found 1 table(s) on page 41\n",
            "Processing page 42...\n",
            "Found 1 table(s) on page 42\n",
            "Processing page 43...\n",
            "Found 1 table(s) on page 43\n",
            "Processing page 44...\n",
            "Found 1 table(s) on page 44\n",
            "Processing page 45...\n",
            "Found 1 table(s) on page 45\n",
            "Processing page 46...\n",
            "Found 1 table(s) on page 46\n",
            "Processing page 47...\n",
            "Found 1 table(s) on page 47\n",
            "Processing page 48...\n",
            "Found 1 table(s) on page 48\n",
            "Processing page 49...\n",
            "Found 1 table(s) on page 49\n",
            "Processing page 50...\n",
            "Found 1 table(s) on page 50\n",
            "Processing page 51...\n",
            "Found 1 table(s) on page 51\n",
            "Processing page 52...\n",
            "Found 1 table(s) on page 52\n",
            "Processing page 53...\n",
            "Found 1 table(s) on page 53\n",
            "Processing page 54...\n",
            "Found 1 table(s) on page 54\n",
            "Processing page 55...\n",
            "Found 1 table(s) on page 55\n",
            "Processing page 56...\n",
            "Found 1 table(s) on page 56\n",
            "Processing page 57...\n",
            "Found 1 table(s) on page 57\n",
            "Processing page 58...\n",
            "Found 1 table(s) on page 58\n",
            "Processing page 59...\n",
            "Found 1 table(s) on page 59\n",
            "Processing page 60...\n",
            "Found 1 table(s) on page 60\n",
            "Processing page 61...\n",
            "Found 1 table(s) on page 61\n",
            "Processing page 62...\n",
            "Found 1 table(s) on page 62\n",
            "Processing page 63...\n",
            "Found 1 table(s) on page 63\n",
            "Processing page 64...\n",
            "Found 1 table(s) on page 64\n",
            "Processing page 65...\n",
            "Found 1 table(s) on page 65\n",
            "Processing page 66...\n",
            "Found 1 table(s) on page 66\n",
            "Processing page 67...\n",
            "Found 1 table(s) on page 67\n",
            "Processing page 68...\n",
            "Found 1 table(s) on page 68\n",
            "Processing page 69...\n",
            "Found 1 table(s) on page 69\n",
            "Processing page 70...\n",
            "Found 1 table(s) on page 70\n",
            "Processing page 71...\n",
            "Found 1 table(s) on page 71\n",
            "Processing page 72...\n",
            "Found 1 table(s) on page 72\n",
            "Processing page 73...\n",
            "Found 1 table(s) on page 73\n",
            "Processing page 74...\n",
            "Found 1 table(s) on page 74\n",
            "Processing page 75...\n",
            "Found 1 table(s) on page 75\n",
            "Processing page 76...\n",
            "Found 1 table(s) on page 76\n",
            "Processing page 77...\n",
            "Found 1 table(s) on page 77\n",
            "Processing page 78...\n",
            "Found 1 table(s) on page 78\n",
            "Processing page 79...\n",
            "Found 1 table(s) on page 79\n",
            "Processing page 80...\n",
            "Found 1 table(s) on page 80\n",
            "Processing page 81...\n",
            "Found 1 table(s) on page 81\n",
            "Processing page 82...\n",
            "Found 1 table(s) on page 82\n",
            "Processing page 83...\n",
            "Found 1 table(s) on page 83\n",
            "Processing page 84...\n",
            "Found 1 table(s) on page 84\n",
            "Processing page 85...\n",
            "Found 1 table(s) on page 85\n",
            "Processing page 86...\n",
            "Found 1 table(s) on page 86\n",
            "Processing page 87...\n",
            "Found 1 table(s) on page 87\n",
            "Processing page 88...\n",
            "Found 1 table(s) on page 88\n",
            "Processing page 89...\n",
            "Found 1 table(s) on page 89\n",
            "Processing page 90...\n",
            "Found 1 table(s) on page 90\n",
            "Processing page 91...\n",
            "Found 1 table(s) on page 91\n",
            "Processing page 92...\n",
            "Found 1 table(s) on page 92\n",
            "Processing page 93...\n",
            "Found 1 table(s) on page 93\n",
            "Processing page 94...\n",
            "Found 1 table(s) on page 94\n",
            "Processing page 95...\n",
            "Found 1 table(s) on page 95\n",
            "Processing page 96...\n",
            "Found 1 table(s) on page 96\n",
            "Processing page 97...\n",
            "Found 1 table(s) on page 97\n",
            "Processing page 98...\n",
            "Found 1 table(s) on page 98\n",
            "Processing page 99...\n",
            "Found 1 table(s) on page 99\n",
            "Processing page 100...\n",
            "Found 1 table(s) on page 100\n",
            "Processing page 101...\n",
            "Found 1 table(s) on page 101\n",
            "Processing page 102...\n",
            "Found 1 table(s) on page 102\n",
            "Processing page 103...\n",
            "Found 1 table(s) on page 103\n",
            "Processing page 104...\n",
            "Found 1 table(s) on page 104\n",
            "Processing page 105...\n",
            "Found 1 table(s) on page 105\n",
            "Processing page 106...\n",
            "Found 1 table(s) on page 106\n",
            "Processing page 107...\n",
            "Found 1 table(s) on page 107\n",
            "Processing page 108...\n",
            "Found 1 table(s) on page 108\n",
            "Processing page 109...\n",
            "Found 1 table(s) on page 109\n",
            "Processing page 110...\n",
            "Found 1 table(s) on page 110\n",
            "Processing page 111...\n",
            "Found 1 table(s) on page 111\n",
            "Processing page 112...\n",
            "Found 1 table(s) on page 112\n",
            "Processing page 113...\n",
            "Found 1 table(s) on page 113\n",
            "Processing page 114...\n",
            "Found 1 table(s) on page 114\n",
            "Processing page 115...\n",
            "Found 1 table(s) on page 115\n",
            "Processing page 116...\n",
            "Found 1 table(s) on page 116\n",
            "Processing page 117...\n",
            "Found 1 table(s) on page 117\n",
            "Processing page 118...\n",
            "Found 1 table(s) on page 118\n",
            "Processing page 119...\n",
            "Found 1 table(s) on page 119\n",
            "Processing page 120...\n",
            "Found 1 table(s) on page 120\n",
            "Processing page 121...\n",
            "Found 1 table(s) on page 121\n",
            "Processing page 122...\n",
            "Found 1 table(s) on page 122\n",
            "Processing page 123...\n",
            "Found 1 table(s) on page 123\n",
            "Processing page 124...\n",
            "Found 1 table(s) on page 124\n",
            "Processing page 125...\n",
            "Found 1 table(s) on page 125\n",
            "Processing page 126...\n",
            "Found 1 table(s) on page 126\n",
            "Processing page 127...\n",
            "Found 1 table(s) on page 127\n",
            "Processing page 128...\n",
            "Found 1 table(s) on page 128\n",
            "Processing page 129...\n",
            "Found 1 table(s) on page 129\n",
            "Processing page 130...\n",
            "Found 1 table(s) on page 130\n",
            "Processing page 131...\n",
            "Found 1 table(s) on page 131\n",
            "Processing page 132...\n",
            "Found 1 table(s) on page 132\n",
            "Processing page 133...\n",
            "Found 1 table(s) on page 133\n",
            "Processing page 134...\n",
            "Found 1 table(s) on page 134\n",
            "Processing page 135...\n",
            "Found 1 table(s) on page 135\n",
            "Processing page 136...\n",
            "Found 1 table(s) on page 136\n",
            "Processing page 137...\n",
            "Found 1 table(s) on page 137\n",
            "Processing page 138...\n",
            "Found 1 table(s) on page 138\n",
            "Processing page 139...\n",
            "Found 1 table(s) on page 139\n",
            "Processing page 140...\n",
            "Found 1 table(s) on page 140\n",
            "Processing page 141...\n",
            "Found 1 table(s) on page 141\n",
            "Processing page 142...\n",
            "Found 1 table(s) on page 142\n",
            "Processing page 143...\n",
            "Found 1 table(s) on page 143\n",
            "Processing page 144...\n",
            "Found 1 table(s) on page 144\n",
            "Processing page 145...\n",
            "Found 1 table(s) on page 145\n",
            "Processing page 146...\n",
            "Found 1 table(s) on page 146\n",
            "Processing page 147...\n",
            "Found 1 table(s) on page 147\n",
            "Processing page 148...\n",
            "Found 1 table(s) on page 148\n",
            "Processing page 149...\n",
            "Found 1 table(s) on page 149\n",
            "Processing page 150...\n",
            "Found 1 table(s) on page 150\n",
            "Processing page 151...\n",
            "Found 1 table(s) on page 151\n",
            "Processing page 152...\n",
            "Found 1 table(s) on page 152\n",
            "Processing page 153...\n",
            "Found 1 table(s) on page 153\n",
            "Processing page 154...\n",
            "Found 1 table(s) on page 154\n",
            "Processing page 155...\n",
            "Found 1 table(s) on page 155\n",
            "Processing page 156...\n",
            "Found 1 table(s) on page 156\n",
            "Processing page 157...\n",
            "Found 1 table(s) on page 157\n",
            "Processing page 158...\n",
            "Found 1 table(s) on page 158\n",
            "Processing page 159...\n",
            "Found 1 table(s) on page 159\n",
            "Processing page 160...\n",
            "Found 1 table(s) on page 160\n",
            "Processing page 161...\n",
            "Found 1 table(s) on page 161\n",
            "Processing page 162...\n",
            "Found 1 table(s) on page 162\n",
            "Processing page 163...\n",
            "Found 1 table(s) on page 163\n",
            "Processing page 164...\n",
            "Found 1 table(s) on page 164\n",
            "Processing page 165...\n",
            "Found 1 table(s) on page 165\n",
            "Processing page 166...\n",
            "Found 1 table(s) on page 166\n",
            "Processing page 167...\n",
            "Found 1 table(s) on page 167\n",
            "Processing page 168...\n",
            "Found 1 table(s) on page 168\n",
            "Processing page 169...\n",
            "Found 1 table(s) on page 169\n",
            "Processing page 170...\n",
            "Found 1 table(s) on page 170\n",
            "Processing page 171...\n",
            "Found 1 table(s) on page 171\n",
            "Processing page 172...\n",
            "Found 1 table(s) on page 172\n",
            "Processing page 173...\n",
            "Found 1 table(s) on page 173\n",
            "Processing page 174...\n",
            "Found 1 table(s) on page 174\n",
            "Processing page 175...\n",
            "Found 1 table(s) on page 175\n",
            "Processing page 176...\n",
            "Found 1 table(s) on page 176\n",
            "Processing page 177...\n",
            "Found 1 table(s) on page 177\n",
            "Processing page 178...\n",
            "Found 1 table(s) on page 178\n",
            "Processing page 179...\n",
            "Found 1 table(s) on page 179\n",
            "Processing page 180...\n",
            "Found 1 table(s) on page 180\n",
            "Processing page 181...\n",
            "Found 1 table(s) on page 181\n",
            "Processing page 182...\n",
            "Found 1 table(s) on page 182\n",
            "Processing page 183...\n",
            "Found 1 table(s) on page 183\n",
            "Processing page 184...\n",
            "Found 1 table(s) on page 184\n",
            "Processing page 185...\n",
            "Found 1 table(s) on page 185\n",
            "Processing page 186...\n",
            "Found 1 table(s) on page 186\n",
            "Processing page 187...\n",
            "Found 1 table(s) on page 187\n",
            "Processing page 188...\n",
            "Found 1 table(s) on page 188\n",
            "Processing page 189...\n",
            "Found 1 table(s) on page 189\n",
            "Processing page 190...\n",
            "Found 1 table(s) on page 190\n",
            "Processing page 191...\n",
            "Found 1 table(s) on page 191\n",
            "Processing page 192...\n",
            "Found 1 table(s) on page 192\n",
            "Processing page 193...\n",
            "Found 1 table(s) on page 193\n",
            "Processing page 194...\n",
            "Found 1 table(s) on page 194\n",
            "Processing page 195...\n",
            "Found 1 table(s) on page 195\n",
            "Processing page 196...\n",
            "Found 1 table(s) on page 196\n",
            "Processing page 197...\n",
            "Found 1 table(s) on page 197\n",
            "Processing page 198...\n",
            "Found 1 table(s) on page 198\n",
            "Processing page 199...\n",
            "Found 1 table(s) on page 199\n",
            "Processing page 200...\n",
            "Found 1 table(s) on page 200\n",
            "Processing page 201...\n",
            "Found 1 table(s) on page 201\n",
            "Processing page 202...\n",
            "Found 1 table(s) on page 202\n",
            "Processing page 203...\n",
            "Found 1 table(s) on page 203\n",
            "Processing page 204...\n",
            "Found 1 table(s) on page 204\n",
            "Processing page 205...\n",
            "Found 1 table(s) on page 205\n",
            "Processing page 206...\n",
            "Found 1 table(s) on page 206\n",
            "Processing page 207...\n",
            "Found 1 table(s) on page 207\n",
            "Processing page 208...\n",
            "Found 1 table(s) on page 208\n",
            "Processing page 209...\n",
            "Found 1 table(s) on page 209\n",
            "Processing page 210...\n",
            "Found 1 table(s) on page 210\n",
            "Processing page 211...\n",
            "Found 1 table(s) on page 211\n",
            "Processing page 212...\n",
            "Found 1 table(s) on page 212\n",
            "Processing page 213...\n",
            "Found 1 table(s) on page 213\n",
            "Processing page 214...\n",
            "Found 1 table(s) on page 214\n",
            "Processing page 215...\n",
            "Found 1 table(s) on page 215\n",
            "Processing page 216...\n",
            "Found 1 table(s) on page 216\n",
            "Processing page 217...\n",
            "Found 1 table(s) on page 217\n",
            "Processing page 218...\n",
            "Found 1 table(s) on page 218\n",
            "Processing page 219...\n",
            "Found 1 table(s) on page 219\n",
            "Processing page 220...\n",
            "Found 1 table(s) on page 220\n",
            "Processing page 221...\n",
            "Found 1 table(s) on page 221\n",
            "Processing page 222...\n",
            "Found 1 table(s) on page 222\n",
            "Processing page 223...\n",
            "Found 1 table(s) on page 223\n",
            "Processing page 224...\n",
            "Found 1 table(s) on page 224\n",
            "Processing page 225...\n",
            "Found 1 table(s) on page 225\n",
            "Processing page 226...\n",
            "Found 1 table(s) on page 226\n",
            "Processing page 227...\n",
            "Found 1 table(s) on page 227\n",
            "Processing page 228...\n",
            "Found 1 table(s) on page 228\n",
            "Processing page 229...\n",
            "Found 1 table(s) on page 229\n",
            "Processing page 230...\n",
            "Found 1 table(s) on page 230\n",
            "Processing page 231...\n",
            "Found 1 table(s) on page 231\n",
            "Processing page 232...\n",
            "Found 1 table(s) on page 232\n",
            "Processing page 233...\n",
            "Found 1 table(s) on page 233\n",
            "Processing page 234...\n",
            "Found 1 table(s) on page 234\n",
            "Processing page 235...\n",
            "Found 1 table(s) on page 235\n",
            "Processing page 236...\n",
            "Found 1 table(s) on page 236\n",
            "Processing page 237...\n",
            "Found 1 table(s) on page 237\n",
            "Processing page 238...\n",
            "Found 1 table(s) on page 238\n",
            "Processing page 239...\n",
            "Found 1 table(s) on page 239\n",
            "Processing page 240...\n",
            "Found 1 table(s) on page 240\n",
            "Processing page 241...\n",
            "Found 1 table(s) on page 241\n",
            "Processing page 242...\n",
            "Found 1 table(s) on page 242\n",
            "Processing page 243...\n",
            "Found 1 table(s) on page 243\n",
            "Processing page 244...\n",
            "Found 1 table(s) on page 244\n",
            "Processing page 245...\n",
            "Found 1 table(s) on page 245\n",
            "Processing page 246...\n",
            "Found 1 table(s) on page 246\n",
            "Processing page 247...\n",
            "Found 1 table(s) on page 247\n",
            "Processing page 248...\n",
            "Found 1 table(s) on page 248\n",
            "Extracted 9075 rows total\n",
            "Sample extracted data:\n",
            "Row 1: {'S_No': '1', 'REGION': 'RIFT VALLEY', 'COUNTY': 'BARINGO', 'SUB_COUNTY': 'BARINGO CENTRAL', 'UIC': '7J98', 'KNEC': '33517209', 'SCHOOL_NAME': 'A I C PHILEMON CHELAGAT GIRLS', 'CLUSTER': 'C3', 'TYPE': 'PUBLIC', 'DISABILITY_TYPE': 'REGULAR', 'ACCOMMODATION_TYPE': 'NONE', 'GENDER': 'BOARDING'}\n",
            "Row 2: {'S_No': '2', 'REGION': 'RIFT VALLEY', 'COUNTY': 'BARINGO', 'SUB_COUNTY': 'BARINGO CENTRAL', 'UIC': 'GMUY', 'KNEC': '33517103', 'SCHOOL_NAME': 'AIC KAPKELELWA SECONDARY SCHOOL', 'CLUSTER': 'C3', 'TYPE': 'PUBLIC', 'DISABILITY_TYPE': 'REGULAR', 'ACCOMMODATION_TYPE': 'NONE', 'GENDER': 'BOARDING'}\n",
            "Row 3: {'S_No': '3', 'REGION': 'RIFT VALLEY', 'COUNTY': 'BARINGO', 'SUB_COUNTY': 'BARINGO CENTRAL', 'UIC': '5XVV', 'KNEC': '33517112', 'SCHOOL_NAME': 'BEKIBON SECONDARY SCHOOL', 'CLUSTER': 'C4', 'TYPE': 'PUBLIC', 'DISABILITY_TYPE': 'REGULAR', 'ACCOMMODATION_TYPE': 'NONE', 'GENDER': 'DAY'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Create DataFrame and preview\n",
        "df = pd.DataFrame(school_data)\n",
        "print(\"Data preview:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjotxbQNp-9U",
        "outputId": "7afdf51d-a9f0-433f-968f-b6a78c8a0405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preview:\n",
            "  S_No       REGION   COUNTY       SUB_COUNTY   UIC      KNEC  \\\n",
            "0    1  RIFT VALLEY  BARINGO  BARINGO CENTRAL  7J98  33517209   \n",
            "1    2  RIFT VALLEY  BARINGO  BARINGO CENTRAL  GMUY  33517103   \n",
            "2    3  RIFT VALLEY  BARINGO  BARINGO CENTRAL  5XVV  33517112   \n",
            "3    4  RIFT VALLEY  BARINGO  BARINGO CENTRAL  5PK2  33517110   \n",
            "4    5  RIFT VALLEY  BARINGO  BARINGO CENTRAL  WDP3  33517223   \n",
            "\n",
            "                           SCHOOL_NAME CLUSTER    TYPE DISABILITY_TYPE  \\\n",
            "0        A I C PHILEMON CHELAGAT GIRLS      C3  PUBLIC         REGULAR   \n",
            "1      AIC KAPKELELWA SECONDARY SCHOOL      C3  PUBLIC         REGULAR   \n",
            "2             BEKIBON SECONDARY SCHOOL      C4  PUBLIC         REGULAR   \n",
            "3  CHEPKERO MIXED DAY SECONDARY SCHOOL      C4  PUBLIC         REGULAR   \n",
            "4  CHESONGO MIXED DAY SECONDARY SCHOOL      C4  PUBLIC         REGULAR   \n",
            "\n",
            "  ACCOMMODATION_TYPE    GENDER  \n",
            "0               NONE  BOARDING  \n",
            "1               NONE  BOARDING  \n",
            "2               NONE       DAY  \n",
            "3               NONE       DAY  \n",
            "4               NONE       DAY  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csv_filename = '/content/drive/MyDrive/Soma/senior-schools-kenya.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "print(f\" Saved to Google Drive: {csv_filename}\")\n",
        "\n",
        "# Also save a local copy for download\n",
        "local_csv = 'senior-schools-kenya.csv'\n",
        "df.to_csv(local_csv, index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "from google.colab import files\n",
        "files.download(local_csv)\n",
        "print(\"ðŸ“¥ Downloaded local copy\")\n",
        "\n",
        "# Cell 8: Display summary statistics\n",
        "print(\"\\nDataset Summary:\")\n",
        "print(f\"Total schools: {len(df)}\")\n",
        "print(f\"Regions: {df['REGION'].nunique()}\")\n",
        "print(f\"Counties: {df['COUNTY'].nunique()}\")\n",
        "print(\"\\nSchools by Region:\")\n",
        "print(df['REGION'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "eTKNvcKYr0wh",
        "outputId": "d54afb9c-6edd-4ed0-80e9-6f21d6832cc4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Saved to Google Drive: /content/drive/MyDrive/Soma/senior-schools-kenya.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8ba9977a-774c-4dbf-87c2-7f71b206070a\", \"senior-schools-kenya.csv\", 931350)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloaded local copy\n",
            "\n",
            "Dataset Summary:\n",
            "Total schools: 9075\n",
            "Regions: 8\n",
            "Counties: 48\n",
            "\n",
            "Schools by Region:\n",
            "REGION\n",
            "RIFT VALLEY      2580\n",
            "EASTERN          1964\n",
            "NYANZA           1566\n",
            "CENTRAL          1108\n",
            "WESTERN          1083\n",
            "COAST             486\n",
            "NORTH EASTERN     180\n",
            "NAIROBI           108\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}